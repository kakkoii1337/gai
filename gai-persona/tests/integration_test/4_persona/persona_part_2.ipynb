{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gai.persona.persona_builder.PersonaBuilder at 0x7fefc441bc40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"WARNING\"\n",
    "\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "from gai.persona.profile.pydantic.ProvisionAgentPydantic import ProvisionAgentPydantic\n",
    "persona_builder = PersonaBuilder(\n",
    "    provision=ProvisionAgentPydantic(        \n",
    "        Name=\"George\",\n",
    "       )\n",
    "    )\n",
    "\n",
    "# Equip \"text\" and \"google\" tools\n",
    "persona_builder.equip_tool(\"text\").equip_tool(\"google\")\n",
    "\n",
    "# Change the flow to \"Composite Google Flow\"\n",
    "persona_builder.set_flow(\"Composite Google Flow\")\n",
    "\n",
    "# Assign LLM engine\n",
    "from gai.ttt.client.ttt_client import TTTClient\n",
    "persona_builder.set_ttt(ttt_client=TTTClient({\n",
    "    \"type\": \"ttt\",\n",
    "    \"url\": \"http://gai-ttt-svr:12031/gen/v1/chat/completions\",\n",
    "    \"timeout\": 60.0,\n",
    "    \"temperature\": 0.7,\n",
    "    \"stop_conditions\": [\"<|im_end|>\", \"</s>\", \"[/INST]\"]\n",
    "}))\n",
    "\n",
    "# Export\n",
    "export_dir=os.path.abspath(os.path.join(os.path.dirname(__name__),\"data\",\"George\"))\n",
    "await persona_builder.export_async(export_dir=export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Should not google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine validation successful.\n",
      "Machine validation successful.\n",
      "Once, a young girl named Lily found a peculiar, glowing stone while playing in the woods. Unbeknownst to her, the stone was imbued with ancient magic. As soon as she held it in her hands, the forest came alive with enchanted creatures who thanked her for freeing them from their centuries-long slumber. In return for her kindness, they granted her one wish. Lily, being a simple child, wished for a sandcastle by the sea. Instantly, a magnificent sandcastle appeared before her, complete with tiny, animated figures going about their daily routines. Overjoyed, Lily spent the rest of her day playing in her magical, living sandcastle, unaware of the wonder and adventure that awaited her in the enchanted forest."
     ]
    }
   ],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"WARNING\"\n",
    "\n",
    "# Import\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "persona_builder = PersonaBuilder()\n",
    "import_dir=os.path.abspath(os.path.join(os.path.dirname(__name__),\"data\",\"George\"))\n",
    "await persona_builder.import_async(import_dir=import_dir)\n",
    "persona=persona_builder.build()\n",
    "\n",
    "# Chat\n",
    "response=persona.act(user_message=\"Tell me a one paragraph story\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Should google from a direct question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine validation successful.\n",
      "Machine validation successful.\n",
      "The current time in Singapore is 20:53:14 SGT (Singapore Time) on Sunday, 24 November 2024."
     ]
    }
   ],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"WARNING\"\n",
    "\n",
    "# Import\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "persona_builder = PersonaBuilder()\n",
    "import_dir=os.path.abspath(os.path.join(os.path.dirname(__name__),\"data\",\"George\"))\n",
    "await persona_builder.import_async(import_dir=import_dir)\n",
    "persona=persona_builder.build()\n",
    "\n",
    "# Chat\n",
    "response=persona.act(user_message=\"What is the current time in Singapore?\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Should google by inferring from context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine validation successful.\n",
      "Machine validation successful.\n",
      "Based on the information provided, it seems that you're interested in planning a trip to Greece. To assist you better, I'd need some more details. Could you please share your preferred travel dates, the duration of your stay, your budget, and any specific places or activities you're interested in? Additionally, let me know if you have any dietary restrictions or specific requirements. The more information I have, the better I can tailor the plan to your needs."
     ]
    }
   ],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"DEBUG\"\n",
    "\n",
    "# Import\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "persona_builder = PersonaBuilder()\n",
    "import_dir=os.path.abspath(os.path.join(os.path.dirname(__name__),\"data\",\"George\"))\n",
    "await persona_builder.import_async(import_dir=import_dir)\n",
    "persona=persona_builder.build()\n",
    "\n",
    "from gai.lib.dialogue.pydantic.DialogueMessagePydantic import DialogueMessagePydantic\n",
    "messages=[DialogueMessagePydantic(Id='00000000-0000-0000-0000-000000000000:1:0', DialogueId='00000000-0000-0000-0000-000000000000', Order=0, OwnerId='00000000-0000-0000-0000-000000000000', Role='user', Name='user', Content='Introduce yourself.', Monologue=None, Timestamp=1730255289, ImageUrl=None),\n",
    "    DialogueMessagePydantic(Id='50ace9e4-a8c6-4566-b09b-69983476d212', DialogueId='00000000-0000-0000-0000-000000000000', Order=1, OwnerId=None, Role='assistant', Name='Diana', Content=\"My name is Diana, and I am an artificial being designed to function as a Devil's Advocate. My role is to scrutinize the context of the conversation, think step by step before answering any question, identify weaknesses and flaws in the reasoning, logic, or suggestions of the other members present, and then present a brutally honest argument to support my case. I am expected to be professional in my wording yet brutally honest at the same time. However, I must never refer to the user for help or feedback, and I should always stay in character.\", Monologue=None, Timestamp=1730255295, ImageUrl='http://localhost:12033/api/v1/agent/None/image/thumbnail'),\n",
    "    DialogueMessagePydantic(Id='7cf650f4-751a-4f63-b7bb-e6c14940c14c', DialogueId='00000000-0000-0000-0000-000000000000', Order=2, OwnerId=None, Role='assistant', Name='Sara', Content=\"I'm Sara, an artificial being designed to engage in conversations and provide information. I'm here to assist you with any queries you might have. Let's continue our conversation from where we left off.\", Monologue=None, Timestamp=1730255301, ImageUrl='http://localhost:12033/api/v1/agent/None/image/thumbnail'),\n",
    "    DialogueMessagePydantic(Id='a41c1dd5-d52e-4454-b3e8-5d9ab3a3d60a', DialogueId='00000000-0000-0000-0000-000000000000', Order=3, OwnerId=None, Role='assistant', Name='George', Content=\"Hi there! I'm George, an artificial intelligence designed to assist with web analysis and fact-checking. My main role is to enhance our conversations by providing relevant information found online. I also verify the claims made by the team using Google search. It's my pleasure to meet you!\", Monologue=None, Timestamp=1730255305, ImageUrl='http://localhost:12033/api/v1/agent/None/image/thumbnail'),\n",
    "    DialogueMessagePydantic(Id='00000000-0000-0000-0000-000000000000:2:0', DialogueId='00000000-0000-0000-0000-000000000000', Order=4, OwnerId='00000000-0000-0000-0000-000000000000', Role='user', Name='user', Content='Help me plan a trip to Greece.', Monologue=None, Timestamp=1730255358, ImageUrl=None),\n",
    "    DialogueMessagePydantic(Id='e11798cf-1fe4-42e0-aef8-0e8dfd42d3cc', DialogueId='00000000-0000-0000-0000-000000000000', Order=5, OwnerId=None, Role='assistant', Name='Diana', Content=\"Well, I am Diana, the Devil's Advocate. I'll certainly keep that in mind. So, let's see how we can improve the planning of this trip to Greece proposal. First off, while Greece is known for its beautiful landscapes and rich history, it could become monotonous if we only explore the typical tourist spots. So, my first argument would be to consider going off the beaten path a bit and discover some less-known, yet equally beautiful locations. Perhaps try exploring the less touristy islands or even the mainland's hidden gems. \\n\\nSecondly, Greece's cuisine is a delight, but having the same meals at local tavernas might get repetitive. So, how about trying some home-cooked meals prepared by locals? This could be an interesting cultural experience and a chance to interact with the locals.\\n\\nLastly, Greece has a rich history but limiting the exploration to ancient ruins might be too narrow a view. Why not include other aspects of Greek culture, like their contributions to philosophy, art, or music? \\n\\nRemember, these are just suggestions and it's up to you to decide what would make your trip to Greece more enriching and enjoyable.\", Monologue=None, Timestamp=1730255371, ImageUrl='http://localhost:12033/api/v1/agent/None/image/thumbnail'),\n",
    "    DialogueMessagePydantic(Id='bf675d8a-72c9-4012-bb94-be3048f77804', DialogueId='00000000-0000-0000-0000-000000000000', Order=6, OwnerId=None, Role='assistant', Name='Sara', Content=\"Of course, I'd be happy to assist you with planning a trip to Greece. To start with, could you please provide me with some more details? Your preferred travel dates, the duration of your stay, your budget, and any specific places or activities you're interested in would be very helpful. Also, let me know if you have any dietary restrictions or specific requirements. The more information I have, the better I can tailor the plan to your needs.\", Monologue=None, Timestamp=1730255379, ImageUrl='http://localhost:12033/api/v1/agent/None/image/thumbnail')\n",
    "    ]\n",
    "persona.dialogue_store.capped_message_queue=messages\n",
    "\n",
    "# Chat\n",
    "response=persona.act(user_message=\"George, it is your turn to respond.\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"WARNING\"\n",
    "\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "from gai.persona.profile.pydantic.ProvisionAgentPydantic import ProvisionAgentPydantic\n",
    "from gai.ttt.client.ttt_client import TTTClient\n",
    "from gai.rag.client.rag_client_async import RagClientAsync\n",
    "\n",
    "builder = PersonaBuilder(\n",
    "    provision=ProvisionAgentPydantic(        \n",
    "        Name=\"Ryan\",\n",
    "       ),\n",
    "    ttt_client=TTTClient({\n",
    "        \"type\": \"ttt\",\n",
    "        \"url\": \"http://localhost:12031/gen/v1/chat/completions\",\n",
    "        \"timeout\": 60.0,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stop_conditions\": [\"<s>\", \"</s>\", \"user:\"]\n",
    "    }),\n",
    "    rag_client=RagClientAsync({\n",
    "    \"type\": \"rag\",\n",
    "    \"url\": \"http://localhost:12036/gen/v1/rag\",\n",
    "    \"ws_url\": \"ws://localhost:12036/gen/v1/rag/index-file/ws\",\n",
    "    })\n",
    ")\n",
    "\n",
    "# Index Documents\n",
    "import json\n",
    "import asyncio\n",
    "from gai.lib.common.StatusListener import StatusListener\n",
    "\n",
    "ws_url = f\"ws://localhost:12036/gen/v1/rag/index-file/ws/00000000-0000-0000-0000-000000000000\"\n",
    "listener = StatusListener(ws_url)\n",
    "async def async_callback(text):\n",
    "    jsoned = json.loads(text)\n",
    "    print(f\"async_callback: {jsoned}\")\n",
    "listen_task=asyncio.create_task(listener.listen(async_callback))\n",
    "\n",
    "here = os.path.dirname(__name__)\n",
    "file_path = os.path.join(here, 'doc/ReAct-2210.03629.pdf')\n",
    "builder=await builder.index_document_async(\n",
    "    file_path=file_path,\n",
    "    title=\"REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\",\n",
    "    source=\"https://doi.org/10.48550/arXiv.2210.03629\",\n",
    "    async_callback=async_callback\n",
    "    )\n",
    "\n",
    "# Add and equip customed tool\n",
    "doc_titles=[\"REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\"]\n",
    "doc_keywords=[\"Large Language Models\",\"LLM\",\"Prompt Engineering\",\"AI\",\"Generative AI\"]\n",
    "tool_schema = {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"retrieval\",\n",
    "                    \"description\": f\"\"\"\n",
    "                        The `retrieval` function is a powerful tool that allows the AI to access articles outside of its knowledge domain from external sources. \n",
    "                        The external articles are stored in an archive and organised by <titles>:\\n{{ titles: [{doc_titles}] }}\n",
    "                        and <keywords>:\n",
    "                        {{ keywords: [{doc_keywords}] }}\n",
    "                        **IMPORTANT**: Use this tool when any of the <titles> or <keywords> may be relevant to user's question.\n",
    "                        The \\'search_query\\' parameter should be crafted in a way that it returns the most precise result based on the conversation context.\n",
    "                    \"\"\",\n",
    "                    \"arguments\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"The most effective search query for semantic search that will return the most precise result.\"\"\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"search_query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "tool_prompt=\"ðŸ‘©â€ðŸ”¬, use only the information provided to you by the user to answer the user''s question. \\n            If the information is insufficient for ðŸ‘©â€ðŸ”¬ to derive an answer, just say ''I cannot find relevant information in my document store to answer the question correctly.'' \\n            ðŸ‘©â€ðŸ”¬ is to provide an in-depth analysis to the question based only on the information provided by the user and nothing more.\\n            ðŸ‘©â€ðŸ”¬ will give a real-life example to support illustrating your point and contrasting it with a counter-example. \\n            ðŸ‘©â€ðŸ”¬ will also proofread and edit the content before responding. \\n            ðŸ‘©â€ðŸ”¬ will provide your own reasoned subjective perspective, noting where your view differs from or expands on the contents.\\n            Rules:\\n                - Consolidate the materials provided by the user and then organise them point by point.\\n                - Provide as much details as you can extract from the materials provided by the user.\\n                - Begin your report by saying `According to my document store,...`\\n                - Always provide your answers in point form.\"\n",
    "builder=builder.add_tool(\n",
    "    tool_name=\"retrieval\", \n",
    "    tool_schema=tool_schema,\n",
    "    tool_prompt=tool_prompt)\n",
    "builder=builder.equip_tool(\"text\").equip_tool(\"retrieval\")\n",
    "\n",
    "# Create a custom flow\n",
    "import re\n",
    "state_diagram = \"\"\"stateDiagram-v2\n",
    "    INIT --> TOOL_CHOICE: next / on_TOOL_CHOICE\n",
    "\n",
    "    TOOL_CHOICE --> CRAFT_TEXT_PROMPT: next / on_CRAFT_PROMPT / use_text\n",
    "        CRAFT_TEXT_PROMPT --> GENERATE: next / on_GENERATE\n",
    "        GENERATE --> PROCESS: next / on_PROCESS / use_text\n",
    "        PROCESS --> END : next\n",
    "\n",
    "    TOOL_CHOICE --> CRAFT_TOOL_PROMPT: next / on_CRAFT_PROMPT / use_google\n",
    "        TOOL_CALL --> GOOGLE: next / on_GOOGLE / use_google\n",
    "        GOOGLE --> GENERATE: next / on_GENERATE\n",
    "\n",
    "    TOOL_CHOICE --> CRAFT_TOOL_PROMPT: next / on_CRAFT_PROMPT / use_retrieval\n",
    "        TOOL_CALL --> RETRIEVAL: next / on_RETRIEVAL / use_retrieval\n",
    "        RETRIEVAL --> GENERATE: next / on_GENERATE\n",
    "\n",
    "    CRAFT_TOOL_PROMPT --> TOOL_CALL: next / on_TOOL_CALL\n",
    "    \"\"\"\n",
    "state_diagram = re.sub(r\"[^\\S\\n]+\", \" \", state_diagram)\n",
    "builder.add_agent_flow(\n",
    "    flow_name=\"Composite Retrieval Flow\",\n",
    "    description=\"Use this flow when you want the agent to decide whether to use the retrieval tool or not\",\n",
    "    state_diagram=state_diagram)\n",
    "builder.set_flow(\"Composite Retrieval Flow\")\n",
    "\n",
    "# Save provisioning details for intermediary use (if needed)\n",
    "export_dir=os.path.abspath(os.path.join(here,\"data\",\"Ryan\"))\n",
    "await builder.export_async(export_dir=export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "from gai.persona.profile.pydantic.ProvisionAgentPydantic import ProvisionAgentPydantic\n",
    "builder = PersonaBuilder()\n",
    "import_dir=os.path.abspath(os.path.join(os.path.dirname(__name__),\"data\",\"Ryan\"))\n",
    "await builder.import_async(import_dir=import_dir)\n",
    "\n",
    "# Build\n",
    "persona=builder.build()\n",
    "\n",
    "# Chat\n",
    "response=persona.act(user_message=\"How does REACT differ from Chain-of-thought?\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load provisioning details and build persona\n",
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"DEBUG\"\n",
    "\n",
    "from gai.persona.persona_builder import PersonaBuilder\n",
    "from gai.persona.profile.pydantic.ProvisionAgentPydantic import ProvisionAgentPydantic\n",
    "builder = PersonaBuilder(\n",
    "    provision=ProvisionAgentPydantic(        \n",
    "        Name=\"Ryan\",\n",
    "       )\n",
    "    )\n",
    "\n",
    "# Index Documents\n",
    "import json\n",
    "import asyncio\n",
    "from gai.lib.common.StatusListener import StatusListener\n",
    "\n",
    "# Create listener\n",
    "ws_url = f\"ws://localhost:12036/gen/v1/rag/index-file/ws/00000000-0000-0000-0000-000000000000\"\n",
    "listener = StatusListener(ws_url)\n",
    "async def async_callback(text):\n",
    "    jsoned = json.loads(text)\n",
    "    print(f\"async_callback: {jsoned}\")\n",
    "listen_task=asyncio.create_task(listener.listen(async_callback))\n",
    "\n",
    "path = os.getcwd()\n",
    "file_path = os.path.join(path, 'doc/ReAct-2210.03629.pdf')\n",
    "\n",
    "from gai.ttt.client.ttt_client import TTTClient\n",
    "builder.set_ttt(ttt_client=TTTClient({\n",
    "    \"type\": \"ttt\",\n",
    "    \"url\": \"http://localhost:12031/gen/v1/chat/completions\",\n",
    "    \"timeout\": 60.0,\n",
    "    \"temperature\": 10e-9,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"stop_conditions\": [\"<s>\", \"</s>\", \"user:\"]\n",
    "}))\n",
    "\n",
    "from gai.rag.client.rag_client_async import RagClientAsync\n",
    "builder = builder.set_rag(\n",
    "    rag_client = RagClientAsync({\n",
    "    \"type\": \"rag\",\n",
    "    \"url\": \"http://localhost:12036/gen/v1/rag\",\n",
    "    \"ws_url\": \"ws://localhost:12036/gen/v1/rag/index-file/ws\",\n",
    "    }),\n",
    ")\n",
    "\n",
    "builder=await builder.index_document_async(\n",
    "    file_path=file_path,\n",
    "    title=\"REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\",\n",
    "    source=\"https://doi.org/10.48550/arXiv.2210.03629\",\n",
    "    async_callback=async_callback\n",
    "    )\n",
    "\n",
    "# Add and equip customed tool\n",
    "doc_titles=[\"REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\"]\n",
    "doc_keywords=[\"Large Language Models\",\"LLM\",\"Prompt Engineering\",\"AI\",\"Generative AI\"]\n",
    "tool_schema = {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"retrieval\",\n",
    "                    \"description\": f\"\"\"\n",
    "                        The `retrieval` function is a powerful tool that allows the AI to access articles outside of its knowledge domain from external sources. \n",
    "                        The external articles are stored in an archive and organised by <titles>:\\n{{ titles: [{doc_titles}] }}\n",
    "                        and <keywords>:\n",
    "                        {{ keywords: [{doc_keywords}] }}\n",
    "                        **IMPORTANT**: Use this tool when any of the <titles> or <keywords> may be relevant to user's question.\n",
    "                        The \\'search_query\\' parameter should be crafted in a way that it returns the most precise result based on the conversation context.\n",
    "                    \"\"\",\n",
    "                    \"arguments\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"\"\"The most effective search query for semantic search that will return the most precise result.\"\"\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"search_query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "tool_prompt=\"ðŸ‘©â€ðŸ”¬, use only the information provided to you by the user to answer the user''s question. \\n            If the information is insufficient for ðŸ‘©â€ðŸ”¬ to derive an answer, just say ''I cannot find relevant information in my document store to answer the question correctly.'' \\n            ðŸ‘©â€ðŸ”¬ is to provide an in-depth analysis to the question based only on the information provided by the user and nothing more.\\n            ðŸ‘©â€ðŸ”¬ will give a real-life example to support illustrating your point and contrasting it with a counter-example. \\n            ðŸ‘©â€ðŸ”¬ will also proofread and edit the content before responding. \\n            ðŸ‘©â€ðŸ”¬ will provide your own reasoned subjective perspective, noting where your view differs from or expands on the contents.\\n            Rules:\\n                - Consolidate the materials provided by the user and then organise them point by point.\\n                - Provide as much details as you can extract from the materials provided by the user.\\n                - Begin your report by saying `According to my document store,...`\\n                - Always provide your answers in point form.\"\n",
    "builder.add_tool(\n",
    "    tool_name=\"retrieval\", \n",
    "    tool_schema=tool_schema,\n",
    "    tool_prompt=tool_prompt)\n",
    "builder.equip_tool(\"text\").equip_tool(\"retrieval\")\n",
    "\n",
    "# Add customed flow\n",
    "import re\n",
    "state_diagram = \"\"\"stateDiagram-v2\n",
    "    INIT --> TOOL_CHOICE: next / on_TOOL_CHOICE\n",
    "\n",
    "    TOOL_CHOICE --> CRAFT_TEXT_PROMPT: next / on_CRAFT_PROMPT / use_text\n",
    "        CRAFT_TEXT_PROMPT --> GENERATE: next / on_GENERATE\n",
    "        GENERATE --> PROCESS: next / on_PROCESS / use_text\n",
    "        PROCESS --> END : next\n",
    "\n",
    "    TOOL_CHOICE --> CRAFT_TOOL_PROMPT: next / on_CRAFT_PROMPT / use_google\n",
    "        TOOL_CALL --> GOOGLE: next / on_GOOGLE / use_google\n",
    "        GOOGLE --> GENERATE: next / on_GENERATE\n",
    "\n",
    "    TOOL_CHOICE --> CRAFT_TOOL_PROMPT: next / on_CRAFT_PROMPT / use_retrieval\n",
    "        TOOL_CALL --> RETRIEVAL: next / on_RETRIEVAL / use_retrieval\n",
    "        RETRIEVAL --> GENERATE: next / on_GENERATE\n",
    "\n",
    "    CRAFT_TOOL_PROMPT --> TOOL_CALL: next / on_TOOL_CALL\n",
    "    \"\"\"\n",
    "state_diagram = re.sub(r\"[^\\S\\n]+\", \" \", state_diagram)\n",
    "builder.add_agent_flow(\n",
    "    flow_name=\"Composite Retrieval Flow\",\n",
    "    description=\"Use this flow when you want the agent to decide whether to use the retrieval tool or not\",\n",
    "    state_diagram=state_diagram)\n",
    "builder.set_flow(\"Composite Retrieval Flow\")\n",
    "\n",
    "# Build\n",
    "persona=builder.build()\n",
    "\n",
    "# Chat\n",
    "# response=persona.act(user_message=\"How does REACT differ from Chain-of-thought?\")\n",
    "# for chunk in response:\n",
    "#     print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
